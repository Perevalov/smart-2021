{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3197ce87-ecd8-47c4-b581-be57b01c4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, TFBertForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback \n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from tensorflow.keras.metrics import FalseNegatives, FalsePositives, TrueNegatives, TruePositives\n",
    "from numba import cuda \n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://webengineering.ins.hs-anhalt.de:41004\")\n",
    "mlflow.set_experiment(\"SMART21: Literal Classifier\")\n",
    "mlflow.tensorflow.autolog()\n",
    "    \n",
    "strategy = tf.distribute.get_strategy()\n",
    "device = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af92c60-2c1b-466c-b269-aad3cff44aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb08df83c5e4eb4b46b04fe5ec7e519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Test dataset:', options=('DBpedia', 'Wikidata'), value='DBpedia')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_name = widgets.RadioButtons(\n",
    "    options=['DBpedia', 'Wikidata'],\n",
    "    description='Test dataset:',\n",
    "    disabled=False\n",
    ")\n",
    "display(test_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ea4f06-27d9-4c5f-81ea-df9c420ad00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edb11fc9c8545ffb852519f4e5a0021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='External Data:', index=(0, 1), options=('DBpedia', 'Wikidata'), value=('DBpedia', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "external_data = widgets.SelectMultiple(\n",
    "    options=['DBpedia', 'Wikidata'],\n",
    "    value=['DBpedia', 'Wikidata'],\n",
    "    #rows=10,\n",
    "    description='External Data:',\n",
    "    disabled=False\n",
    ")\n",
    "display(external_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87866c1-152f-4b0e-9888-c079fcf474a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9534f42fb482db7978dea0b733231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Model:', options=('bert-base-cased',), value='bert-base-cased')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = widgets.RadioButtons(\n",
    "    options=['bert-base-cased'],\n",
    "    description='Model:',\n",
    "    disabled=False\n",
    ")\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596c9e32-37bf-45c9-96d7-e414b0b735a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2bb351593d4c44ad6fbc5e00a1d4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, continuous_update=False, description='EPOCHS:', max=20, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='EPOCHS:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5d60a3-03da-43b9-89fe-76be264a964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = model.value\n",
    "EPOCHS = epochs.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2327c50-2df0-4e6a-9c18-8a1683d61db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e16874e-cfaa-49e7-bc3a-717e655637d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    \"\"\"\n",
    "    encodes text for a model\n",
    "    \"\"\"\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4618b59-2ec8-4055-9f4a-2ede96096a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512, hidden_dim=32, n_classes=1):\n",
    "    \"\"\"\n",
    "    builds a model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    \n",
    "    if n_classes == 2: # binary classification\n",
    "        out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    else:\n",
    "        out = Dense(n_classes, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    \n",
    "    if n_classes > 2:\n",
    "        model.compile(\n",
    "            Adam(lr=1e-5),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['categorical_accuracy']\n",
    "        )\n",
    "    else:\n",
    "        model.compile(\n",
    "            Adam(lr=1e-5),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', FalseNegatives(), FalsePositives(), TrueNegatives(), TruePositives()]\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07186d66-09e8-4dfd-9796-2bb84d213a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123b52a-92ec-4460-8504-a06461716c58",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa78cae-f622-4fa8-8ac5-ac1fa0311ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbp_df = pd.read_csv(\"../../data/at/dbpedia/task1_dbpedia_train_cleaned.csv\", sep='$')\n",
    "wdt_df = pd.read_csv(\"../../data/at/wikidata/task1_wikidata_train_cleaned.csv\", sep='$')\n",
    "\n",
    "dbp_df.id = dbp_df.id.apply(lambda x: str(x) + \"-dbp\")\n",
    "wdt_df.id = dbp_df.id.apply(lambda x: str(x) + \"-wdt\")\n",
    "\n",
    "dbp_df = dbp_df[dbp_df.category == 'literal']\n",
    "wdt_df = wdt_df[wdt_df.category == 'literal']\n",
    "\n",
    "data_dict = {\n",
    "    'DBpedia': dbp_df,\n",
    "    'Wikidata': wdt_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49129ccc-d650-422e-820a-99928464389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_external_data(df):\n",
    "    for k in external_data.value:\n",
    "        if k != test_data_name.value:\n",
    "            df = df.append(data_dict[k])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "090c26a0-9b3e-41eb-8599-8771a2006eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = list()\n",
    "\n",
    "for q in add_external_data(data_dict[test_data_name.value]).question.values:\n",
    "    max_len.append(len(tokenizer.encode(q)))\n",
    "    \n",
    "MAX_LEN = np.array(max_len).max()\n",
    "del max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75722f71-a934-4df3-8098-d14f619929b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(data_dict[test_data_name.value].question, data_dict[test_data_name.value].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57184992-bb51-4bec-a4d9-6a4515c0e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(data_dict[test_data_name.value].id, data_dict[test_data_name.value].type):\n",
    "    train_df = add_external_data(data_dict[test_data_name.value].iloc[train_index])\n",
    "    test_df = data_dict[test_data_name.value].iloc[test_index]\n",
    "    train_df = train_df[~train_df.question.isin(test_df.question)]\n",
    "    train_list.append(train_df)\n",
    "    test_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22ae4a76-f5c6-4e92-9d96-3b2442d71dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1406, 4), (6338, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list[0].shape, train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e5a6c1-80b9-48fe-b776-7bd2eb90b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "2021-08-19 17:47:05.587102: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-19 17:47:05.587246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.588006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.08GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\n",
      "2021-08-19 17:47:05.588035: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-19 17:47:05.590598: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-19 17:47:05.590633: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-19 17:47:05.592054: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-19 17:47:05.592249: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-19 17:47:05.592605: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-19 17:47:05.593150: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-19 17:47:05.594973: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-19 17:47:05.595139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.596306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.597797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-19 17:47:05.598508: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-19 17:47:05.599401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.600298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.08GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\n",
      "2021-08-19 17:47:05.600419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.601289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.602045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-19 17:47:05.602099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-19 17:47:05.986610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 17:47:05.986633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-19 17:47:05.986638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-19 17:47:05.986830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.987495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.987910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-19 17:47:05.988403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5866 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Super with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "tf_train_list, tf_test_list, lens, y_test_list = list(), list(), list(), list()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_list[0].type.values.tolist() + test_list[0].type.values.tolist())\n",
    "    \n",
    "for i in range(n_splits):\n",
    "    x_train = regular_encode(train_list[i].question.values.tolist(), tokenizer, maxlen=MAX_LEN)\n",
    "    x_test = regular_encode(test_list[i].question.values.tolist(), tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "    y_train = train_list[i].type.values\n",
    "    y_test = test_list[i].type.values\n",
    "\n",
    "    # encode textual labels into corresponding numbers\n",
    "    \n",
    "    encoded_y_train = encoder.transform(y_train) \n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    dummy_y_train = np_utils.to_categorical(encoded_y_train, num_classes=encoder.classes_.shape[0]) # one hot encoded\n",
    "    dummy_y_test = np_utils.to_categorical(encoded_y_test, num_classes=encoder.classes_.shape[0]) # one hot encoded\n",
    "    \n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, dummy_y_train))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_test, dummy_y_test))\n",
    "        .batch(BATCH_SIZE)\n",
    "    )\n",
    "    \n",
    "    tf_train_list.append(train_dataset)\n",
    "    tf_test_list.append(test_dataset)\n",
    "    lens.append(x_train.shape)\n",
    "    y_test_list.append(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd58eb3-bf10-4b36-9bc2-0072b858acda",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee70d4e-9f5e-45ff-b007-0085c9377d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f3948111d44e9dab940984fe8d5f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, continuous_update=False, description='N_SPLIT:', max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_idx = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=n_splits-1,\n",
    "    step=1,\n",
    "    description='N_SPLIT:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67883b-a7e8-4fa9-9564-399e5d08c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:47:15.071276: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-19 17:47:15.490355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f974490ae80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f974490ae80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 145)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 108310272 \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 5383      \n",
      "=================================================================\n",
      "Total params: 108,315,655\n",
      "Trainable params: 108,315,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:47:20.181046: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-19 17:47:20.181119: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-19 17:47:20.181207: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-08-19 17:47:20.181789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2021-08-19 17:47:20.183398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:47:20.408487: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-08-19 17:47:20.408668: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021/08/19 17:47:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:791: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:47:27.794147: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-19 17:47:27.877409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2699905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/396 [..............................] - ETA: 1:06:51 - loss: 1.6845 - categorical_accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:47:31.136279: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-19 17:47:31.136305: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/396 [..............................] - ETA: 5:45 - loss: 1.5123 - categorical_accuracy: 0.2500   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:47:31.665620: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-08-19 17:47:31.666300: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-08-19 17:47:31.719237: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2833 callback api events and 2858 activity events. \n",
      "2021-08-19 17:47:31.769271: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-08-19 17:47:31.839323: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31\n",
      "2021-08-19 17:47:31.882059: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.trace.json.gz\n",
      "2021-08-19 17:47:31.975152: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31\n",
      "2021-08-19 17:47:31.982731: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.memory_profile.json.gz\n",
      "2021-08-19 17:47:31.986011: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31Dumped tool data for xplane.pb to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /tmp/tmp9yqnj2kg/train/plugins/profile/2021_08_19_17_47_31/ins-alex-ThinkPad-T15g-Gen-1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/396 [..............................] - ETA: 3:21 - loss: 1.3737 - categorical_accuracy: 0.3021WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1930s vs `on_train_batch_end` time: 0.2379s). Check your callbacks.\n",
      "396/396 [==============================] - ETA: 0s - loss: 0.3831 - categorical_accuracy: 0.8333WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "396/396 [==============================] - 156s 370ms/step - loss: 0.3831 - categorical_accuracy: 0.8333 - val_loss: 0.1451 - val_categorical_accuracy: 0.9552\n",
      "Epoch 2/10\n",
      "363/396 [==========================>...] - ETA: 11s - loss: 0.1116 - categorical_accuracy: 0.9657"
     ]
    }
   ],
   "source": [
    "i = split_idx.value\n",
    "\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, max_len=MAX_LEN, n_classes=encoder.classes_.shape[0])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=1,\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"EPOCHS\", EPOCHS)\n",
    "    mlflow.log_param(\"BATCH_SIZE\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"MAX_LEN\", MAX_LEN)\n",
    "    mlflow.log_param(\"MODEL\", MODEL)\n",
    "    mlflow.log_param(\"TEST_DATA\", test_data_name.value)\n",
    "    mlflow.log_param(\"EXTERNAL_DATA\", '+'.join(d for d in external_data.value))\n",
    "    mlflow.log_param(\"n_split_idx\", i)\n",
    "\n",
    "    n_steps = lens[0][0] // BATCH_SIZE # determine number of steps per epoch\n",
    "\n",
    "    train_history = model.fit(\n",
    "        tf_train_list[i],\n",
    "        steps_per_epoch=n_steps,\n",
    "        validation_data=tf_test_list[i],\n",
    "        callbacks=[early_stopping],\n",
    "        epochs=EPOCHS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbe44a-50a8-4fba-8fe1-d64fad952802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
