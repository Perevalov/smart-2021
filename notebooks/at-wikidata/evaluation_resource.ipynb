{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3197ce87-ecd8-47c4-b581-be57b01c4b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:11:56.718129: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, TFBertForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback \n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from tensorflow.keras.metrics import FalseNegatives, FalsePositives, TrueNegatives, TruePositives\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from numba import cuda \n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://webengineering.ins.hs-anhalt.de:41004\")\n",
    "mlflow.set_experiment(\"SMART21: Resource Classifier\")\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "strategy = tf.distribute.get_strategy()\n",
    "device = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af92c60-2c1b-466c-b269-aad3cff44aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf01247770645178cc0fa1610c8ff3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Test dataset:', options=('Wikidata',), value='Wikidata')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_name = widgets.RadioButtons(\n",
    "    options=['Wikidata'],\n",
    "    description='Test dataset:',\n",
    "    disabled=False\n",
    ")\n",
    "display(test_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ea4f06-27d9-4c5f-81ea-df9c420ad00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f25d4a9ca424a94a4b310e769cbaf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='External Data:', index=(0,), options=('Wikidata', 'LC-QuAD2', 'WikidataTranslated'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "external_data = widgets.SelectMultiple(\n",
    "    options=['Wikidata', 'LC-QuAD2', 'WikidataTranslated'],\n",
    "    value=['Wikidata'],\n",
    "    #rows=10,\n",
    "    description='External Data:',\n",
    "    disabled=False\n",
    ")\n",
    "display(external_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87866c1-152f-4b0e-9888-c079fcf474a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a75a99d2b477f9aab1028e12aa129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Model:', options=('bert-base-cased', 'bert-base-multilingual-cased'), value='bert-ba…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = widgets.RadioButtons(\n",
    "    options=['bert-base-cased', 'bert-base-multilingual-cased'],\n",
    "    description='Model:',\n",
    "    disabled=False\n",
    ")\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596c9e32-37bf-45c9-96d7-e414b0b735a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd271a6831b46ad85cac7c32f52de63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, continuous_update=False, description='EPOCHS:', max=20, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='EPOCHS:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d5d60a3-03da-43b9-89fe-76be264a964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = model.value\n",
    "EPOCHS = epochs.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2327c50-2df0-4e6a-9c18-8a1683d61db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e16874e-cfaa-49e7-bc3a-717e655637d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    \"\"\"\n",
    "    encodes text for a model\n",
    "    \"\"\"\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4618b59-2ec8-4055-9f4a-2ede96096a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512, hidden_dim=32, n_classes=1):\n",
    "    \"\"\"\n",
    "    builds a model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    \n",
    "    if n_classes == 2: # binary classification\n",
    "        out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    else:\n",
    "        out = Dense(n_classes, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    \n",
    "    if n_classes > 2: # multilabel\n",
    "        model.compile(\n",
    "            Adam(lr=1e-5),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['categorical_accuracy']\n",
    "        )\n",
    "    else:\n",
    "        model.compile(\n",
    "            Adam(lr=1e-5),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', FalseNegatives(), FalsePositives(), TrueNegatives(), TruePositives()]\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07186d66-09e8-4dfd-9796-2bb84d213a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123b52a-92ec-4460-8504-a06461716c58",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba7e989-b5b7-4a60-9628-234a45e18410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_resource_class(x):\n",
    "    lst = ast.literal_eval(x)\n",
    "    lst = [str(l) for l in lst]\n",
    "    if len(lst) > 0:\n",
    "        return str(sorted(lst))\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "def sort_type(data_frame):\n",
    "    data_frame = pd.DataFrame.copy(data_frame)\n",
    "    data_frame = data_frame[data_frame.category == 'resource']\n",
    "    data_frame.type = data_frame.type.apply(lambda x: convert_str_to_resource_class(x))\n",
    "    data_frame = data_frame[data_frame.type != 'NULL']\n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def prepare_wdt_df(df):\n",
    "    sample_amounts = dict()\n",
    "    for i,j in sort_type(df).type.value_counts().iteritems():\n",
    "        sample_amounts[i] = j\n",
    "    cutoff_rate = np.percentile(list(sample_amounts.values()), 95)\n",
    "    included_types = list()\n",
    "    for i, j in sample_amounts.items():\n",
    "        if j > cutoff_rate:\n",
    "            included_types.append(i)\n",
    "\n",
    "    df = sort_type(df)\n",
    "    df_person = df[df.type == \"['natural person', 'omnivore', 'person']\"].sample(frac=0.3)\n",
    "    df = df[(df.type.isin(included_types)) & (df.type != \"['natural person', 'omnivore', 'person']\")]\n",
    "    df = df.append(df_person)\n",
    "    df = df.sample(frac=1)\n",
    "    df.type = df.type.apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caa78cae-f622-4fa8-8ac5-ac1fa0311ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdt_df = pd.read_csv(\"../../data/at/wikidata/lcquad2_anstype_wikidata_train_cleaned.csv\", sep='$')\n",
    "lcquad2_df = pd.read_csv(\"../../data/at/common/lcquad2_train_types-1.csv\", sep='$')\n",
    "wdt_translated_df = pd.read_csv(\"../../data/at/wikidata/lcquad2_anstype_wikidata_train_translated.csv\", sep='$')\n",
    "\n",
    "wdt_df = prepare_wdt_df(wdt_df)\n",
    "lcquad2_df = prepare_wdt_df(lcquad2_df)\n",
    "wdt_translated_df = prepare_wdt_df(wdt_translated_df)\n",
    "\n",
    "langs = ['de', 'es', 'zh', 'it', 'ro', 'vi', 'ru', 'fr', 'cs', 'jap']\n",
    "\n",
    "wdt_tmp = wdt_translated_df.copy()\n",
    "\n",
    "for l in langs:\n",
    "    wdt_tmp['question'] = wdt_tmp[f'question_{l}']\n",
    "    wdt_translated_df = wdt_translated_df.append(wdt_tmp)\n",
    "     \n",
    "wdt_translated_df = wdt_translated_df[wdt_df.columns].sample(frac=0.5)\n",
    "\n",
    "# wdt_df.id = wdt_df.id.apply(lambda x: str(x) + \"-wdt\")\n",
    "# wdt_df = wdt_df[wdt_df.category == 'resource']\n",
    "# wdt_df.type = wdt_df.type.apply(lambda x: list(ast.literal_eval(x)))\n",
    "# wdt_df_columns = wdt_df.columns\n",
    "# wdt_df_columns = list(wdt_df_columns)\n",
    "# wdt_df_columns[2] = '_category_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e12d4775-442a-4941-a455-129a9e27e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(np.append(wdt_df.type.values, lcquad2_df.type.values))\n",
    "np.save('../../data/bin/label_encoders/wdt_lcquad_encoder.npy', mlb.classes_)\n",
    "\n",
    "# wdt_df_dummies = pd.DataFrame(mlb.transform(wdt_df.type), columns=mlb.classes_)\n",
    "# wdt_df_dummies = pd.get_dummies(wdt_df.type.apply(pd.Series).stack()).sum(level=0)\n",
    "# wdt_df = pd.concat([wdt_df.reset_index(drop=True), wdt_df_dummies.reset_index(drop=True)], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acbdae71-2074-48ad-aca3-83aad764758e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed1f6418-0add-4bfe-9be5-7e181804694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wdt_df.columns = list(wdt_df_columns) + list(wdt_df_dummies.columns)\n",
    "wdt_df.id = wdt_df.id.astype(int)\n",
    "wdt_df.category = wdt_df.category.astype(str)\n",
    "\n",
    "data_dict = {\n",
    "    'Wikidata': wdt_df,\n",
    "    'WikidataTranslated': wdt_translated_df,\n",
    "    'LC-QuAD2': lcquad2_df\n",
    "}\n",
    "# wdt_df_dummies.shape, wdt_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49129ccc-d650-422e-820a-99928464389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_external_data(df):\n",
    "    for k in external_data.value:\n",
    "        if k != test_data_name.value:\n",
    "            df = df.append(data_dict[k])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "090c26a0-9b3e-41eb-8599-8771a2006eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = list()\n",
    "\n",
    "for q in add_external_data(data_dict[test_data_name.value]).question.values:\n",
    "    max_len.append(len(tokenizer.encode(q)))\n",
    "    \n",
    "MAX_LEN = np.array(max_len).max()\n",
    "del max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e1b6a0-d947-402b-9638-ea61d038614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75722f71-a934-4df3-8098-d14f619929b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(data_dict[test_data_name.value].id, data_dict[test_data_name.value].category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57184992-bb51-4bec-a4d9-6a4515c0e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(data_dict[test_data_name.value].id, data_dict[test_data_name.value].category):\n",
    "    train_df = add_external_data(data_dict[test_data_name.value].iloc[train_index])\n",
    "    test_df = data_dict[test_data_name.value].iloc[test_index]\n",
    "    train_df = train_df[~train_df.question.isin(test_df.question)]\n",
    "    train_list.append(train_df)\n",
    "    test_list.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22ae4a76-f5c6-4e92-9d96-3b2442d71dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1539, 4), (3251, 4))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list[0].shape, train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1e5a6c1-80b9-48fe-b776-7bd2eb90b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "2021-10-05 12:16:38.992541: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-05 12:16:38.993288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:38.993674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.08GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\n",
      "2021-10-05 12:16:38.993701: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-05 12:16:39.025343: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-05 12:16:39.025483: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-05 12:16:39.036269: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-05 12:16:39.039423: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-05 12:16:39.041983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-05 12:16:39.046725: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-05 12:16:39.047527: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-05 12:16:39.047653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.048266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.049039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-05 12:16:39.049902: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-05 12:16:39.050470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.051117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.08GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\n",
      "2021-10-05 12:16:39.051212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.051666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.052078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-05 12:16:39.052388: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-05 12:16:39.689226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-05 12:16:39.689249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-10-05 12:16:39.689255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-10-05 12:16:39.689423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.689798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.690123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-05 12:16:39.690416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5956 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Super with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "tf_train_list, tf_test_list, lens = list(), list(), list()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(train_list[0].type.values.tolist() + test_list[0].type.values.tolist())\n",
    "    \n",
    "for i in range(n_splits):\n",
    "    x_train = regular_encode(train_list[i].question.values.tolist(), tokenizer, maxlen=MAX_LEN)\n",
    "    x_test = regular_encode(test_list[i].question.values.tolist(), tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "    dummy_y_train = mlb.transform(train_list[i].type)\n",
    "    dummy_y_test = mlb.transform(test_list[i].type)\n",
    "    \n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, dummy_y_train))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_test, dummy_y_test))\n",
    "        .batch(BATCH_SIZE)\n",
    "    )\n",
    "    \n",
    "    tf_train_list.append(train_dataset)\n",
    "    tf_test_list.append(test_dataset)\n",
    "    lens.append(x_train.shape)\n",
    "    # y_test_list.append(dummy_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd58eb3-bf10-4b36-9bc2-0072b858acda",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ee70d4e-9f5e-45ff-b007-0085c9377d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9b5511948148f69ae1ac9b849b2220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, continuous_update=False, description='N_SPLIT:', max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_idx = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=n_splits-1,\n",
    "    step=1,\n",
    "    description='N_SPLIT:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d67883b-a7e8-4fa9-9564-399e5d08c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:16:44.949216: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-05 12:16:45.746830: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f666a12de80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f666a12de80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 145)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 108310272 \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 305)               234545    \n",
      "=================================================================\n",
      "Total params: 108,544,817\n",
      "Trainable params: 108,544,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:16:51.420939: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-10-05 12:16:51.420993: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-10-05 12:16:51.422968: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-10-05 12:16:51.423432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2021-10-05 12:16:51.442183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:16:51.665216: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-10-05 12:16:51.665405: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021/10/05 12:16:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:791: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:17:00.072197: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-05 12:17:00.172147: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2699905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/203 [..............................] - ETA: 38:13 - loss: 0.7650 - categorical_accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:17:05.091192: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-10-05 12:17:05.091280: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/203 [..............................] - ETA: 7:56 - loss: 0.7516 - categorical_accuracy: 0.0312 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:17:06.120050: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-10-05 12:17:06.120929: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-10-05 12:17:06.197529: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2857 callback api events and 2882 activity events. \n",
      "2021-10-05 12:17:06.255763: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-10-05 12:17:06.337638: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06\n",
      "2021-10-05 12:17:06.380648: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.trace.json.gz\n",
      "2021-10-05 12:17:06.500018: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06\n",
      "2021-10-05 12:17:06.508113: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.memory_profile.json.gz\n",
      "2021-10-05 12:17:06.512057: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06Dumped tool data for xplane.pb to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /tmp/tmp67y7zc4r/train/plugins/profile/2021_10_05_12_17_06/ins-alex-ThinkPad-T15g-Gen-1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/203 [..............................] - ETA: 2:42 - loss: 0.7032 - categorical_accuracy: 0.0208WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2086s vs `on_train_batch_end` time: 0.4162s). Check your callbacks.\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.2558 - categorical_accuracy: 0.0175WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "203/203 [==============================] - 119s 531ms/step - loss: 0.2558 - categorical_accuracy: 0.0175 - val_loss: 0.1473 - val_categorical_accuracy: 0.1137\n",
      "Epoch 2/10\n",
      "203/203 [==============================] - 106s 522ms/step - loss: 0.1219 - categorical_accuracy: 0.0810 - val_loss: 0.0939 - val_categorical_accuracy: 0.1144\n",
      "Epoch 3/10\n",
      "203/203 [==============================] - 90s 445ms/step - loss: 0.0836 - categorical_accuracy: 0.0930 - val_loss: 0.0710 - val_categorical_accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "203/203 [==============================] - 79s 391ms/step - loss: 0.0663 - categorical_accuracy: 0.0714 - val_loss: 0.0601 - val_categorical_accuracy: 0.1144\n",
      "Epoch 5/10\n",
      "203/203 [==============================] - 83s 407ms/step - loss: 0.0573 - categorical_accuracy: 0.0634 - val_loss: 0.0542 - val_categorical_accuracy: 0.0091\n",
      "Epoch 6/10\n",
      "203/203 [==============================] - 79s 392ms/step - loss: 0.0521 - categorical_accuracy: 0.0674 - val_loss: 0.0492 - val_categorical_accuracy: 0.1007\n",
      "Epoch 7/10\n",
      "203/203 [==============================] - 80s 392ms/step - loss: 0.0466 - categorical_accuracy: 0.1151 - val_loss: 0.0453 - val_categorical_accuracy: 0.2014\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 12:27:40.945346: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppxjfs2y0/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppxjfs2y0/model/data/model/assets\n",
      "2021/10/05 12:28:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:805: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n",
      "2021/10/05 12:28:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:601: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n"
     ]
    }
   ],
   "source": [
    "i = split_idx.value\n",
    "\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, max_len=MAX_LEN, n_classes=dummy_y_train.shape[1])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=1,\n",
    "    min_delta=0.005,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"EPOCHS\", EPOCHS)\n",
    "    mlflow.log_param(\"BATCH_SIZE\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"MAX_LEN\", MAX_LEN)\n",
    "    mlflow.log_param(\"MODEL\", MODEL)\n",
    "    mlflow.log_param(\"TEST_DATA\", test_data_name.value)\n",
    "    mlflow.log_param(\"EXTERNAL_DATA\", '+'.join(d for d in external_data.value))\n",
    "    mlflow.log_param(\"n_split_idx\", i)\n",
    "\n",
    "    n_steps = lens[0][0] // BATCH_SIZE # determine number of steps per epoch\n",
    "\n",
    "    train_history = model.fit(\n",
    "        tf_train_list[i],\n",
    "        steps_per_epoch=n_steps,\n",
    "        validation_data=tf_test_list[i],\n",
    "        callbacks=[early_stopping],\n",
    "        epochs=EPOCHS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dcbe44a-50a8-4fba-8fe1-d64fad952802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ins-alex/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('natural person', 'omnivore', 'person')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = regular_encode([\"in what newspaper did obama printed\"], tokenizer, maxlen=MAX_LEN)\n",
    "res = model.predict(x_pred)\n",
    "res[res <= 0.1] = 0\n",
    "res[res > 0.1] = 1\n",
    "\n",
    "mlb.inverse_transform(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "019a1c01-1b6c-4712-ad39-6600ecad0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/bin/resource_wikidata_base_2020_lcquad/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/bin/resource_wikidata_base_2020_lcquad/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f'../../data/bin/resource_wikidata_base_2020_lcquad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c5b9d-9c43-409b-a20d-f48b011ba099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
