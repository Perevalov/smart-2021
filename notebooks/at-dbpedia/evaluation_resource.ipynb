{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3197ce87-ecd8-47c4-b581-be57b01c4b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:28:42.282201: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, TFBertForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from numba import cuda \n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import ast\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://webengineering.ins.hs-anhalt.de:41004\")\n",
    "mlflow.set_experiment(\"SMART21: Resource Classifier\")\n",
    "mlflow.tensorflow.autolog()\n",
    "    \n",
    "strategy = tf.distribute.get_strategy()\n",
    "device = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229d3fc1-ed0d-4ad4-a233-d8ddbf23f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76402b6390564e4290e2b36ebf894121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='External Data:', index=(0,), options=('DBpedia2020', 'LC-QuAD', 'DBpediaTranslated…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "external_data = widgets.SelectMultiple(\n",
    "    options=['DBpedia2020', 'LC-QuAD', 'DBpediaTranslated'],\n",
    "    value=['DBpedia2020'],\n",
    "    #rows=10,\n",
    "    description='External Data:',\n",
    "    disabled=False\n",
    ")\n",
    "display(external_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d83d140-69da-4fab-98f5-bb88c67741ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa99601b80b4c0bb148c66fea9596cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Model:', options=('bert-base-cased', 'bert-base-multilingual-cased'), value='bert-ba…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = widgets.RadioButtons(\n",
    "    options=['bert-base-cased', 'bert-base-multilingual-cased'],\n",
    "    description='Model:',\n",
    "    disabled=False\n",
    ")\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e16874e-cfaa-49e7-bc3a-717e655637d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    \"\"\"\n",
    "    encodes text for a model\n",
    "    \"\"\"\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4618b59-2ec8-4055-9f4a-2ede96096a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512, hidden_dim=32, n_classes=1):\n",
    "    \"\"\"\n",
    "    builds a model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    \n",
    "    if n_classes == 2: # binary classification\n",
    "        out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    else:\n",
    "        out = Dense(n_classes, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    \n",
    "    if n_classes > 2:\n",
    "        model.compile(\n",
    "            Adam(lr=1e-5),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['categorical_accuracy']\n",
    "        )\n",
    "    else:\n",
    "        model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2327c50-2df0-4e6a-9c18-8a1683d61db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "MODEL = model.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07186d66-09e8-4dfd-9796-2bb84d213a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123b52a-92ec-4460-8504-a06461716c58",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c479a987-1c81-49dc-9fed-86d81787bc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_str_to_resource_class(x):\n",
    "    lst = ast.literal_eval(x)\n",
    "    \n",
    "    if len(lst) > 0:\n",
    "        return lst[0]\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "def convert_df_for_resource_training(data_frame):\n",
    "    data_frame = pd.DataFrame.copy(data_frame)\n",
    "    data_frame = data_frame[data_frame.category == 'resource']\n",
    "    data_frame.type = data_frame.type.apply(lambda x: convert_str_to_resource_class(x))\n",
    "    data_frame = data_frame[data_frame.type != 'NULL']\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa78cae-f622-4fa8-8ac5-ac1fa0311ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ins-alex/.local/lib/python3.8/site-packages/pandas/core/frame.py:7134: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return concat(\n"
     ]
    }
   ],
   "source": [
    "dbp_df = pd.read_csv(\"../../data/at/dbpedia/smarttask_dbpedia_train_cleaned.csv\", sep='$')\n",
    "lcquad_df = pd.read_csv(\"../../data/at/common/lcquad_train_types.csv\", sep='$')\n",
    "dbp_translated_df = pd.read_csv(\"../../data/at/dbpedia/task1_dbpedia_train_translated.csv\", sep='$')\n",
    "\n",
    "langs = ['de', 'es', 'zh', 'it', 'ro', 'vi', 'ru', 'fr', 'cs', 'jap']\n",
    "\n",
    "dbp_tmp = dbp_translated_df.copy()\n",
    "\n",
    "for l in langs:\n",
    "    dbp_tmp['question'] = dbp_tmp[f'question_{l}']\n",
    "    dbp_translated_df = dbp_df.append(dbp_tmp)\n",
    "     \n",
    "dbp_translated_df = dbp_translated_df[dbp_df.columns].sample(frac=1)\n",
    "\n",
    "data_dict = {\n",
    "    'DBpedia2020': dbp_df,\n",
    "    'LC-QuAD': lcquad_df,\n",
    "    'DBpediaTranslated': dbp_translated_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df6a5e39-2343-4c1b-87d9-825c4fe4827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_external_data(df):\n",
    "    for k in external_data.value:\n",
    "        df = df.append(data_dict[k][df.columns])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "090c26a0-9b3e-41eb-8599-8771a2006eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = list()\n",
    "\n",
    "for q in add_external_data(dbp_df).question.values:\n",
    "    max_len.append(len(tokenizer.encode(q)))\n",
    "    \n",
    "MAX_LEN = np.array(max_len).max()\n",
    "del max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b700e49-c2ab-4e72-a2c7-f8cb87e18a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75722f71-a934-4df3-8098-d14f619929b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(dbp_df.id, dbp_df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57184992-bb51-4bec-a4d9-6a4515c0e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(dbp_df.id, dbp_df.category):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_df = add_external_data(dbp_df.iloc[train_index])\n",
    "    test_df = dbp_df.iloc[test_index]\n",
    "    train_df = train_df[~train_df.question.isin(test_df.question)]\n",
    "    train_list.append(convert_df_for_resource_training(train_df))\n",
    "    test_list.append(convert_df_for_resource_training(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9c0258-d51d-43fb-9119-ad51d0e2c341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13875, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e5a6c1-80b9-48fe-b776-7bd2eb90b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "2021-10-04 22:29:09.017484: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-04 22:29:09.017615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.017960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.08GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\n",
      "2021-10-04 22:29:09.017979: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-04 22:29:09.020703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-04 22:29:09.020737: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-04 22:29:09.022100: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-04 22:29:09.022292: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-04 22:29:09.022640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-04 22:29:09.023162: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-04 22:29:09.023250: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-04 22:29:09.023317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.023671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.023957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-04 22:29:09.024250: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-04 22:29:09.024677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.024974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Super with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.08GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\n",
      "2021-10-04 22:29:09.025017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.025410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.025695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-04 22:29:09.025718: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-04 22:29:09.379166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-04 22:29:09.379185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-10-04 22:29:09.379191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-10-04 22:29:09.379348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.379715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.380033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-04 22:29:09.380332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6250 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Super with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "tf_train_list, tf_test_list, lens, y_test_list = list(), list(), list(), list()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_list[0].type.values.tolist() + test_list[0].type.values.tolist() + train_list[1].type.values.tolist() + test_list[1].type.values.tolist())\n",
    "np.save('../../data/bin/label_encoders/dbp_encoder_2020_lcquad_translated.npy', encoder.classes_)\n",
    "\n",
    "for i in range(n_splits):\n",
    "    x_train = regular_encode(train_list[i].question.values.tolist(), tokenizer, maxlen=MAX_LEN)\n",
    "    x_test = regular_encode(test_list[i].question.values.tolist(), tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "    y_train = train_list[i].type.values\n",
    "    y_test = test_list[i].type.values\n",
    "\n",
    "    # encode textual labels into corresponding numbers\n",
    "    \n",
    "    encoded_y_train = encoder.transform(y_train) \n",
    "    encoded_y_test = encoder.transform(y_test)\n",
    "    dummy_y_train = np_utils.to_categorical(encoded_y_train, num_classes=encoder.classes_.shape[0])\n",
    "    dummy_y_test = np_utils.to_categorical(encoded_y_test, num_classes=encoder.classes_.shape[0]) # one hot encoded\n",
    "    \n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, dummy_y_train))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_test, dummy_y_test))\n",
    "        .batch(BATCH_SIZE)\n",
    "    )\n",
    "    \n",
    "    tf_train_list.append(train_dataset)\n",
    "    tf_test_list.append(test_dataset)\n",
    "    lens.append(x_train.shape)\n",
    "    y_test_list.append(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd58eb3-bf10-4b36-9bc2-0072b858acda",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e21ea048-97d9-48a0-993c-11c5f9838c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def __init__(self, val_data, average='micro', mlflow=None, **kwargs):\n",
    "        super(Metrics, self).__init__(**kwargs)\n",
    "        self.validation_data = val_data\n",
    "        self.average = average\n",
    "        self.mlflow = mlflow\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batches = len(self.validation_data)\n",
    "        total = batches * BATCH_SIZE\n",
    "\n",
    "        y_pred = np.array([])\n",
    "        y_true = np.array([])\n",
    "\n",
    "        for xVal, yVal in self.validation_data:\n",
    "            y_pred = np.append(y_pred, np.argmax(self.model.predict(xVal), axis=1)).astype('int32')\n",
    "            y_true = np.append(y_true, np.argmax(yVal, axis=1)).astype('int32')\n",
    "        \n",
    "        _val_f1 = f1_score(y_true, y_pred, average=self.average)\n",
    "        _val_recall = recall_score(y_true, y_pred, average=self.average)\n",
    "        _val_precision = precision_score(y_true, y_pred, average=self.average)\n",
    "        \n",
    "        if self.mlflow:\n",
    "            mlflow.log_metric(\"val_f1\", _val_f1)\n",
    "            mlflow.log_metric(\"val_precision\", _val_recall)\n",
    "            mlflow.log_metric(\"val_recall\", _val_precision)\n",
    "            \n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        \n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d67883b-a7e8-4fa9-9564-399e5d08c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:56:35.104377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-04 20:56:35.880857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff312e9fe80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff312e9fe80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 145)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 177853440 \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 309)               237621    \n",
      "=================================================================\n",
      "Total params: 178,091,061\n",
      "Trainable params: 178,091,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:56:42.155313: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-10-04 20:56:42.155333: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-10-04 20:56:42.156621: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-10-04 20:56:42.156811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2021-10-04 20:56:42.164717: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:56:42.383828: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-10-04 20:56:42.384013: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021/10/04 20:56:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:791: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:56:51.316954: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-04 20:56:51.409341: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2699905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3150 [..............................] - ETA: 10:14:18 - loss: 6.0583 - categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:56:55.191918: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-10-04 20:56:55.191944: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/3150 [..............................] - ETA: 50:43 - loss: 5.8137 - categorical_accuracy: 0.0000e+00   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 20:56:55.772716: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-10-04 20:56:55.773591: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-10-04 20:56:55.830669: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2833 callback api events and 2858 activity events. \n",
      "2021-10-04 20:56:55.895515: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-10-04 20:56:55.980582: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55\n",
      "2021-10-04 20:56:56.026420: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.trace.json.gz\n",
      "2021-10-04 20:56:56.135912: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55\n",
      "2021-10-04 20:56:56.144794: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.memory_profile.json.gz\n",
      "2021-10-04 20:56:56.148623: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55Dumped tool data for xplane.pb to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /tmp/tmprqrpi0lo/train/plugins/profile/2021_10_04_20_56_55/ins-alex-ThinkPad-T15g-Gen-1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/3150 [..............................] - ETA: 29:34 - loss: 5.2833 - categorical_accuracy: 0.1667 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2031s vs `on_train_batch_end` time: 0.2682s). Check your callbacks.\n",
      "3150/3150 [==============================] - ETA: 0s - loss: 2.7108 - categorical_accuracy: 0.4216WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "3150/3150 [==============================] - 1294s 407ms/step - loss: 2.7108 - categorical_accuracy: 0.4216 - val_loss: 1.8156 - val_categorical_accuracy: 0.6021\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      " — val_f1: 0.602076 — val_precision: 0.602076 — val_recall 0.602076\n",
      "Epoch 2/10\n",
      "3150/3150 [==============================] - 1336s 424ms/step - loss: 1.9044 - categorical_accuracy: 0.5577 - val_loss: 1.6299 - val_categorical_accuracy: 0.6442\n",
      " — val_f1: 0.644228 — val_precision: 0.644228 — val_recall 0.644228\n",
      "Epoch 3/10\n",
      "3150/3150 [==============================] - 1340s 426ms/step - loss: 1.5776 - categorical_accuracy: 0.6247 - val_loss: 1.7134 - val_categorical_accuracy: 0.6675\n",
      "Restoring model weights from the end of the best epoch.\n",
      " — val_f1: 0.644228 — val_precision: 0.644228 — val_recall 0.644228\n",
      "Epoch 00003: early stopping\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:04:37.802388: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8wloxsf6/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8wloxsf6/model/data/model/assets\n",
      "2021/10/04 22:05:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:805: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n",
      "2021/10/04 22:05:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ins-alex/.local/lib/python3.8/site-packages/mlflow/tensorflow.py:601: UserWarning: Logging to MLflow failed: [Errno 13] Permission denied: '/data'\"\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"N_SPLIT\"] = \"0\"\n",
    "i = int(os.environ.get('N_SPLIT'))\n",
    "\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, max_len=MAX_LEN, n_classes=encoder.classes_.shape[0])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=1,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"KG\", \"DBpedia\")\n",
    "    mlflow.log_param(\"EPOCHS\", EPOCHS)\n",
    "    mlflow.log_param(\"BATCH_SIZE\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"MAX_LEN\", MAX_LEN)\n",
    "    mlflow.log_param(\"MODEL\", MODEL)\n",
    "    mlflow.log_param(\"DATA\", str(external_data.value))\n",
    "    mlflow.log_param(\"n_split_idx\", i)\n",
    "\n",
    "    n_steps = lens[0][0] // BATCH_SIZE # determine number of steps per epoch\n",
    "    \n",
    "    train_history = model.fit(\n",
    "        tf_train_list[i],\n",
    "        steps_per_epoch=n_steps,\n",
    "        validation_data=tf_test_list[i],\n",
    "        callbacks=[early_stopping, Metrics(tf_test_list[i], mlflow=mlflow)],\n",
    "        epochs=EPOCHS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be361e75-bdc2-4f54-86e5-2fceb677574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
      "/home/ins-alex/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/bin/resource_dbpedia_base_2020_lcquad_translated/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/bin/resource_dbpedia_base_2020_lcquad_translated/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f'../../data/bin/resource_dbpedia_base_2020_lcquad_translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309914e5-4bce-4d47-9f29-2449442e6a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
