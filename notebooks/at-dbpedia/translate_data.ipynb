{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86674efa-bf53-498d-b163-81420646d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331ca6e3-7bc1-453a-ba5d-7927573e557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langs = ['de', 'es', 'zh', 'it', 'ro', 'vi', 'ru', 'fr', 'cs', 'jap']\n",
    "langs = ['fr', 'cs', 'jap']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdb6e7bc-4f57-4cea-9585-ed20a0109ba6",
   "metadata": {},
   "source": [
    "# download models\n",
    "for lang in langs:\n",
    "    MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-en-{lang}')\n",
    "    MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-en-{lang}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7fa3a1-a3f1-471e-b650-6a5b1fbfb9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      24033\n",
       "question    What are the military operation which start wi...\n",
       "category                                             resource\n",
       "type                                                ['event']\n",
       "Name: 151, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500d02dc-a6bc-474d-ac86-1b74c88570c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/at/wikidata/lcquad2_anstype_wikidata_train_translated.csv\", sep='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14db61a-7ac1-47d8-86fe-d7bebfc34235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>question_de</th>\n",
       "      <th>question_es</th>\n",
       "      <th>question_zh</th>\n",
       "      <th>question_it</th>\n",
       "      <th>question_ro</th>\n",
       "      <th>question_vi</th>\n",
       "      <th>question_ru</th>\n",
       "      <th>question_fr</th>\n",
       "      <th>question_cs</th>\n",
       "      <th>question_jap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19719</td>\n",
       "      <td>What periodical literature does Delta Air Line...</td>\n",
       "      <td>resource</td>\n",
       "      <td>['publication', 'recurring', 'intellectual wor...</td>\n",
       "      <td>Welche periodische Literatur verwendet Delta A...</td>\n",
       "      <td>¿Qué literatura periódica usa Delta Air Lines ...</td>\n",
       "      <td>三角洲航空公司用什么定期文献作为模具?</td>\n",
       "      <td>Quale letteratura periodica usa Delta Air Line...</td>\n",
       "      <td>Ce literatură periodică foloseşte Delta Air Li...</td>\n",
       "      <td>Không gian thiên văn học dùng để làm đồ trang ...</td>\n",
       "      <td>Какая периодическая литература используется De...</td>\n",
       "      <td>Quelle littérature périodique Delta Air Lines ...</td>\n",
       "      <td>Jakou periodickou literaturu používá Delta Air...</td>\n",
       "      <td>生れ た 田畑 は, どこ に あ る か. しゃこ を し た 網 の よう に,  祝福...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15554</td>\n",
       "      <td>Who is the child of Ranavalona I's husband?</td>\n",
       "      <td>resource</td>\n",
       "      <td>['person', 'omnivore', 'natural person']</td>\n",
       "      <td>Wer ist das Kind von Ranavalona I.'s Ehemann?</td>\n",
       "      <td>¿Quién es el hijo del marido de Ranavalona I?</td>\n",
       "      <td>我的丈夫拉纳瓦洛纳的孩子是谁?</td>\n",
       "      <td>Chi è il figlio del marito di Ranavalona I?</td>\n",
       "      <td>Cine e copilul soţului Ranavalonei?</td>\n",
       "      <td>Ai là con trai của Raonan Chồng của em?</td>\n",
       "      <td>Кто ребёнок Ранавалоны я муж?</td>\n",
       "      <td>Qui est l'enfant du mari de Ranavalona?</td>\n",
       "      <td>Kdo je syn Ranavalony, manžela?</td>\n",
       "      <td>種 を ま く 者 の 子 は だれ か. わたし に は その 夫 の 子 が あ る の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>974</td>\n",
       "      <td>Is it true Jeff_Bridges occupation Lane Chandl...</td>\n",
       "      <td>boolean</td>\n",
       "      <td>['boolean']</td>\n",
       "      <td>Ist es wahr Jeff_Bridges Besetzung Lane Chandl...</td>\n",
       "      <td>¿Es verdad la ocupación de Jeff_Bridges Lane C...</td>\n",
       "      <td>这是真的杰夫布里奇占领 莱恩钱德勒和摄影师?</td>\n",
       "      <td>È vero Jeff_Bridges occupazione Lane Chandler ...</td>\n",
       "      <td>E adevărat că Jeff_Bridges se ocupă de Lane Ch...</td>\n",
       "      <td>Có thật là Jeff _Bridges làm việc với Chandler...</td>\n",
       "      <td>Это правда, что Джефф_Бриджс оккупирует Лейн Ч...</td>\n",
       "      <td>Est-ce vrai Jeff_Bridges occupation Lane Chand...</td>\n",
       "      <td>Je pravda, Jeff_Bridges povolání Lane Chandler...</td>\n",
       "      <td>これ は 真実 で あ る. すなわち レパイム び と ピセバび と, ザレア び と, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27610</td>\n",
       "      <td>Which is the operating income for Qantas?</td>\n",
       "      <td>literal</td>\n",
       "      <td>['number']</td>\n",
       "      <td>Welches ist das operative Ergebnis für Qantas?</td>\n",
       "      <td>¿Cuál es el ingreso operativo de Qantas?</td>\n",
       "      <td>Qantas的营业收入是多少?</td>\n",
       "      <td>Qual è il reddito operativo per Qantas?</td>\n",
       "      <td>Care este venitul din exploatare pentru Qantas?</td>\n",
       "      <td>Thu nhập của Qas là bao nhiêu?</td>\n",
       "      <td>Какой операционный доход для Кантаса?</td>\n",
       "      <td>Quel est le revenu d'exploitation de Qantas?</td>\n",
       "      <td>Jaký je provozní příjem pro Qantas?</td>\n",
       "      <td>むなし い 争い に よ っ て 人 は, 寒 さ に よ っ て 耕 す こと が でき ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24488</td>\n",
       "      <td>which cola starts with the letter p</td>\n",
       "      <td>resource</td>\n",
       "      <td>['soft drink', 'trademark', 'carbonated bevera...</td>\n",
       "      <td>welche Cola mit dem Buchstaben p beginnt</td>\n",
       "      <td>que la cola comienza con la letra p</td>\n",
       "      <td>以字母 p 开头的可口可乐</td>\n",
       "      <td>quale cola inizia con la lettera p</td>\n",
       "      <td>care cola începe cu litera p</td>\n",
       "      <td>mà trong đó khởi khởi khởi khởi khởi động bằng...</td>\n",
       "      <td>Которая начинается с буквы p</td>\n",
       "      <td>qui commence par la lettre p</td>\n",
       "      <td>který Cola začíná písmenem p</td>\n",
       "      <td>彼 は 密接 も し て 神 の み 旨 を 聞 き いれ た.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  category  \\\n",
       "0  19719  What periodical literature does Delta Air Line...  resource   \n",
       "1  15554        Who is the child of Ranavalona I's husband?  resource   \n",
       "2    974  Is it true Jeff_Bridges occupation Lane Chandl...   boolean   \n",
       "3  27610          Which is the operating income for Qantas?   literal   \n",
       "4  24488                which cola starts with the letter p  resource   \n",
       "\n",
       "                                                type  \\\n",
       "0  ['publication', 'recurring', 'intellectual wor...   \n",
       "1           ['person', 'omnivore', 'natural person']   \n",
       "2                                        ['boolean']   \n",
       "3                                         ['number']   \n",
       "4  ['soft drink', 'trademark', 'carbonated bevera...   \n",
       "\n",
       "                                         question_de  \\\n",
       "0  Welche periodische Literatur verwendet Delta A...   \n",
       "1      Wer ist das Kind von Ranavalona I.'s Ehemann?   \n",
       "2  Ist es wahr Jeff_Bridges Besetzung Lane Chandl...   \n",
       "3     Welches ist das operative Ergebnis für Qantas?   \n",
       "4           welche Cola mit dem Buchstaben p beginnt   \n",
       "\n",
       "                                         question_es             question_zh  \\\n",
       "0  ¿Qué literatura periódica usa Delta Air Lines ...     三角洲航空公司用什么定期文献作为模具?   \n",
       "1      ¿Quién es el hijo del marido de Ranavalona I?         我的丈夫拉纳瓦洛纳的孩子是谁?   \n",
       "2  ¿Es verdad la ocupación de Jeff_Bridges Lane C...  这是真的杰夫布里奇占领 莱恩钱德勒和摄影师?   \n",
       "3           ¿Cuál es el ingreso operativo de Qantas?         Qantas的营业收入是多少?   \n",
       "4                que la cola comienza con la letra p           以字母 p 开头的可口可乐   \n",
       "\n",
       "                                         question_it  \\\n",
       "0  Quale letteratura periodica usa Delta Air Line...   \n",
       "1        Chi è il figlio del marito di Ranavalona I?   \n",
       "2  È vero Jeff_Bridges occupazione Lane Chandler ...   \n",
       "3            Qual è il reddito operativo per Qantas?   \n",
       "4                 quale cola inizia con la lettera p   \n",
       "\n",
       "                                         question_ro  \\\n",
       "0  Ce literatură periodică foloseşte Delta Air Li...   \n",
       "1                Cine e copilul soţului Ranavalonei?   \n",
       "2  E adevărat că Jeff_Bridges se ocupă de Lane Ch...   \n",
       "3    Care este venitul din exploatare pentru Qantas?   \n",
       "4                       care cola începe cu litera p   \n",
       "\n",
       "                                         question_vi  \\\n",
       "0  Không gian thiên văn học dùng để làm đồ trang ...   \n",
       "1            Ai là con trai của Raonan Chồng của em?   \n",
       "2  Có thật là Jeff _Bridges làm việc với Chandler...   \n",
       "3                     Thu nhập của Qas là bao nhiêu?   \n",
       "4  mà trong đó khởi khởi khởi khởi khởi động bằng...   \n",
       "\n",
       "                                         question_ru  \\\n",
       "0  Какая периодическая литература используется De...   \n",
       "1                      Кто ребёнок Ранавалоны я муж?   \n",
       "2  Это правда, что Джефф_Бриджс оккупирует Лейн Ч...   \n",
       "3              Какой операционный доход для Кантаса?   \n",
       "4                       Которая начинается с буквы p   \n",
       "\n",
       "                                         question_fr  \\\n",
       "0  Quelle littérature périodique Delta Air Lines ...   \n",
       "1            Qui est l'enfant du mari de Ranavalona?   \n",
       "2  Est-ce vrai Jeff_Bridges occupation Lane Chand...   \n",
       "3       Quel est le revenu d'exploitation de Qantas?   \n",
       "4                       qui commence par la lettre p   \n",
       "\n",
       "                                         question_cs  \\\n",
       "0  Jakou periodickou literaturu používá Delta Air...   \n",
       "1                    Kdo je syn Ranavalony, manžela?   \n",
       "2  Je pravda, Jeff_Bridges povolání Lane Chandler...   \n",
       "3                Jaký je provozní příjem pro Qantas?   \n",
       "4                       který Cola začíná písmenem p   \n",
       "\n",
       "                                        question_jap  \n",
       "0  生れ た 田畑 は, どこ に あ る か. しゃこ を し た 網 の よう に,  祝福...  \n",
       "1  種 を ま く 者 の 子 は だれ か. わたし に は その 夫 の 子 が あ る の...  \n",
       "2  これ は 真実 で あ る. すなわち レパイム び と ピセバび と, ザレア び と, ...  \n",
       "3  むなし い 争い に よ っ て 人 は, 寒 さ に よ っ て 耕 す こと が でき ...  \n",
       "4                   彼 は 密接 も し て 神 の み 旨 を 聞 き いれ た.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e1300f-13ec-4f4b-a8a6-c25934157c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056f5e8423324debb04e5999fd7ff117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ins-alex/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "2021-10-16 18:07:17.195568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7073/261628090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Perform the translation and decode the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtranslation_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             )\n\u001b[0;32m-> 1053\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1054\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m             )  # (batch_size * num_beams, vocab_size)\n\u001b[1;32m   1809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeam_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mbanned_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_banned_bad_words_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_scores_to_inf_for_banned_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m_set_scores_to_inf_for_banned_tokens\u001b[0;34m(self, scores, banned_tokens)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         banned_mask = (\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lang in langs:\n",
    "    model = MarianMTModel.from_pretrained(f'Helsinki-NLP/opus-mt-en-{lang}').to(device)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-en-{lang}')\n",
    "    translation_list = list()\n",
    "    \n",
    "    for text in tqdm(train.question.values):\n",
    "        # Tokenize the text\n",
    "        batch = tokenizer([text], return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        # Make sure that the tokenized text does not exceed the maximum\n",
    "        # allowed size of 512\n",
    "        batch[\"input_ids\"] = batch[\"input_ids\"][:, :512]\n",
    "        batch[\"attention_mask\"] = batch[\"attention_mask\"][:, :512]\n",
    "        # Perform the translation and decode the output\n",
    "        translation = model.generate(**batch)\n",
    "        translation_list.append(tokenizer.batch_decode(translation, skip_special_tokens=True)[0])\n",
    "        \n",
    "    train[f'question_{lang}'] = translation_list\n",
    "    train.to_csv(\"../../data/at/wikidata/lcquad2_anstype_wikidata_train_translated.csv\", sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e7ff3-e69b-400e-a370-19c2716820fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
